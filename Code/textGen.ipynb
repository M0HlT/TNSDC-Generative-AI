{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import collections\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "CONFIG_number_of_words = 3\n",
        "CONFIG_batch_size = 200\n",
        "CONFIG_hidden_size = 1500\n",
        "CONFIG_num_epochs = 50\n",
        "CONFIG_learning_rate = 0.0001\n",
        "CONFIG_learning_rate_decay = 0\n",
        "\n",
        "\n",
        "data_path = os.path.join(os.getcwd(), 'data')\n",
        "\n",
        "\n",
        "def load_dictionary(path):\n",
        "    return json.loads(open(path).read())\n",
        "\n",
        "\n",
        "def read_words(filename):\n",
        "    with tf.io.gfile.GFile(filename, 'r') as f:\n",
        "        return f.read().replace('\\n', '<eos>').split()\n",
        "\n",
        "\n",
        "def build_vocab(filename):\n",
        "    data = read_words(filename)\n",
        "\n",
        "    counter = collections.Counter(data)\n",
        "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
        "\n",
        "    words, _ = list(zip(*count_pairs))\n",
        "    word_to_id = dict(zip(words, range(len(words))))\n",
        "\n",
        "    return word_to_id\n",
        "\n",
        "\n",
        "def file_to_word_ids(filename, word_to_id):\n",
        "    data = read_words(filename)\n",
        "    return [word_to_id[word] for word in data if word in word_to_id]\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    train_path = os.path.join(data_path, 'ptb.train.txt')\n",
        "    valid_path = os.path.join(data_path, 'ptb.valid.txt')\n",
        "\n",
        "    word_to_id = build_vocab(train_path)\n",
        "    train_data = file_to_word_ids(train_path, word_to_id)\n",
        "    valid_data = file_to_word_ids(valid_path, word_to_id)\n",
        "    total_words = len(word_to_id)\n",
        "    reversed_dictionary = dict(zip(word_to_id.values(), word_to_id.keys()))\n",
        "    dictionary = {value: key for key, value in reversed_dictionary.items()}\n",
        "\n",
        "    print('\\ntotalwords : ', total_words, '\\n')\n",
        "    return train_data, valid_data, total_words, reversed_dictionary, dictionary\n",
        "\n",
        "\n",
        "def save_json(dictionary, filename):\n",
        "    with open(filename, 'w') as fp:\n",
        "        json.dump(dictionary, fp)\n",
        "\n",
        "\n",
        "class BatchGenerator(object):\n",
        "\n",
        "    def __init__(self, data, num_steps, batch_size, total_words, skip_step=5):\n",
        "        self.data = data\n",
        "        self.num_steps = num_steps\n",
        "        self.batch_size = batch_size\n",
        "        self.total_words = total_words\n",
        "        self.current_idx = 0\n",
        "        self.skip_step = skip_step\n",
        "\n",
        "    def generate(self):\n",
        "        x = np.zeros((self.batch_size, self.num_steps))\n",
        "        y = np.zeros((self.batch_size, self.num_steps, self.total_words))\n",
        "        while True:\n",
        "            for i in range(self.batch_size):\n",
        "                if self.current_idx + self.num_steps >= len(self.data):\n",
        "                    self.current_idx = 0\n",
        "                x[i, :] = self.data[self.current_idx:self.current_idx + self.num_steps]\n",
        "                temp_y = self.data[self.current_idx +\n",
        "                                   1:self.current_idx + self.num_steps + 1]\n",
        "                y[i, :, :] = tf.keras.utils.to_categorical(\n",
        "                    temp_y, num_classes=self.total_words)\n",
        "                self.current_idx += self.skip_step\n",
        "            yield x, y\n",
        "\n",
        "\n",
        "def create_model(total_words, hidden_size, num_steps, optimizer='adam'):\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # Embedding layer / Input layer\n",
        "    model.add(tf.keras.layers.Embedding(\n",
        "        total_words, hidden_size, input_length=num_steps))\n",
        "\n",
        "    # 4 LSTM layers\n",
        "    model.add(tf.keras.layers.LSTM(units=hidden_size, return_sequences=True))\n",
        "    model.add(tf.keras.layers.LSTM(units=hidden_size, return_sequences=True))\n",
        "    model.add(tf.keras.layers.LSTM(units=hidden_size, return_sequences=True))\n",
        "    model.add(tf.keras.layers.LSTM(units=hidden_size, return_sequences=True))\n",
        "\n",
        "    # Fully Connected layer\n",
        "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1024)))\n",
        "    model.add(tf.keras.layers.Activation('relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.3, seed=0))\n",
        "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(512)))\n",
        "    model.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(tf.keras.layers.TimeDistributed(\n",
        "        tf.keras.layers.Dense(total_words)))\n",
        "    model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
        "                  metrics=[tf.keras.metrics.categorical_accuracy])\n",
        "    return model\n",
        "\n",
        "train_data, valid_data, total_words, indexToString, stringToIndex = load_data()\n",
        "\n",
        "train_data_generator = BatchGenerator(\n",
        "    train_data, CONFIG_number_of_words, CONFIG_batch_size, total_words, skip_step=CONFIG_number_of_words)\n",
        "valid_data_generator = BatchGenerator(\n",
        "    valid_data, CONFIG_number_of_words, CONFIG_batch_size, total_words, skip_step=CONFIG_number_of_words)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=CONFIG_learning_rate)\n",
        "model = create_model(total_words=total_words, hidden_size=CONFIG_hidden_size,num_steps=CONFIG_number_of_words, optimizer=optimizer)\n",
        "print(model.summary())\n",
        "\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join('/content/model/checkpoint', 'model-{epoch:02d}.keras'), verbose=1)\n",
        "\n",
        "save_json(stringToIndex, os.path.join(\n",
        "    os.getcwd(), 'data', 'stringToIndex.json'))\n",
        "\n",
        "save_json(indexToString, os.path.join(\n",
        "    os.getcwd(), 'data', 'indexToString.json'))\n",
        "\n",
        "model.fit(\n",
        "    train_data_generator.generate(),\n",
        "    steps_per_epoch=len(train_data) // (CONFIG_batch_size * CONFIG_number_of_words),\n",
        "    epochs=CONFIG_num_epochs,\n",
        "    validation_data=valid_data_generator.generate(),\n",
        "    validation_steps=len(valid_data) // (CONFIG_batch_size * CONFIG_number_of_words),\n",
        "    callbacks=[checkpointer],\n",
        ")\n",
        "\n",
        "\n",
        "model.save(os.path.join ('/content/model/', 'model.keras'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgaIt-kp3Gbr",
        "outputId": "41ffca05-29ed-4baf-fb3a-c048c6c67f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "totalwords :  9948 \n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 3, 1500)           14922000  \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 3, 1500)           18006000  \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 3, 1500)           18006000  \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 3, 1500)           18006000  \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 3, 1500)           18006000  \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 3, 1024)           1537024   \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " activation (Activation)     (None, 3, 1024)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 3, 1024)           0         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDi  (None, 3, 512)            524800    \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 3, 512)            0         \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDi  (None, 3, 9948)           5103324   \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 3, 9948)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 94111148 (359.01 MB)\n",
            "Trainable params: 94111148 (359.01 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 6.6425 - categorical_accuracy: 0.0615\n",
            "Epoch 1: saving model to /content/model/checkpoint/model-01.keras\n",
            "1273/1273 [==============================] - 229s 172ms/step - loss: 6.6425 - categorical_accuracy: 0.0615 - val_loss: 6.3507 - val_categorical_accuracy: 0.0908\n",
            "Epoch 2/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 6.1517 - categorical_accuracy: 0.1174\n",
            "Epoch 2: saving model to /content/model/checkpoint/model-02.keras\n",
            "1273/1273 [==============================] - 199s 156ms/step - loss: 6.1517 - categorical_accuracy: 0.1174 - val_loss: 6.0388 - val_categorical_accuracy: 0.1293\n",
            "Epoch 3/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 5.9046 - categorical_accuracy: 0.1378\n",
            "Epoch 3: saving model to /content/model/checkpoint/model-03.keras\n",
            "1273/1273 [==============================] - 205s 161ms/step - loss: 5.9046 - categorical_accuracy: 0.1378 - val_loss: 5.8875 - val_categorical_accuracy: 0.1428\n",
            "Epoch 4/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 5.7381 - categorical_accuracy: 0.1491\n",
            "Epoch 4: saving model to /content/model/checkpoint/model-04.keras\n",
            "1273/1273 [==============================] - 201s 158ms/step - loss: 5.7381 - categorical_accuracy: 0.1491 - val_loss: 5.7975 - val_categorical_accuracy: 0.1507\n",
            "Epoch 5/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 5.6126 - categorical_accuracy: 0.1559\n",
            "Epoch 5: saving model to /content/model/checkpoint/model-05.keras\n",
            "1273/1273 [==============================] - 197s 154ms/step - loss: 5.6126 - categorical_accuracy: 0.1559 - val_loss: 5.7483 - val_categorical_accuracy: 0.1542\n",
            "Epoch 6/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 5.5070 - categorical_accuracy: 0.1621\n",
            "Epoch 6: saving model to /content/model/checkpoint/model-06.keras\n",
            "1273/1273 [==============================] - 212s 167ms/step - loss: 5.5070 - categorical_accuracy: 0.1621 - val_loss: 5.7127 - val_categorical_accuracy: 0.1598\n",
            "Epoch 7/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 5.4026 - categorical_accuracy: 0.1690\n",
            "Epoch 7: saving model to /content/model/checkpoint/model-07.keras\n",
            "1273/1273 [==============================] - 207s 162ms/step - loss: 5.4026 - categorical_accuracy: 0.1690 - val_loss: 5.6750 - val_categorical_accuracy: 0.1667\n",
            "Epoch 8/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 5.3071 - categorical_accuracy: 0.1754\n",
            "Epoch 8: saving model to /content/model/checkpoint/model-08.keras\n",
            "1273/1273 [==============================] - 200s 157ms/step - loss: 5.3071 - categorical_accuracy: 0.1754 - val_loss: 5.6441 - val_categorical_accuracy: 0.1714\n",
            "Epoch 9/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 5.2184 - categorical_accuracy: 0.1806\n",
            "Epoch 9: saving model to /content/model/checkpoint/model-09.keras\n",
            "1273/1273 [==============================] - 204s 161ms/step - loss: 5.2184 - categorical_accuracy: 0.1806 - val_loss: 5.6427 - val_categorical_accuracy: 0.1743\n",
            "Epoch 10/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 5.1370 - categorical_accuracy: 0.1848\n",
            "Epoch 10: saving model to /content/model/checkpoint/model-10.keras\n",
            "1273/1273 [==============================] - 197s 154ms/step - loss: 5.1370 - categorical_accuracy: 0.1848 - val_loss: 5.6522 - val_categorical_accuracy: 0.1764\n",
            "Epoch 11/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 5.0605 - categorical_accuracy: 0.1887\n",
            "Epoch 11: saving model to /content/model/checkpoint/model-11.keras\n",
            "1273/1273 [==============================] - 211s 166ms/step - loss: 5.0605 - categorical_accuracy: 0.1887 - val_loss: 5.6833 - val_categorical_accuracy: 0.1795\n",
            "Epoch 12/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.9874 - categorical_accuracy: 0.1918\n",
            "Epoch 12: saving model to /content/model/checkpoint/model-12.keras\n",
            "1273/1273 [==============================] - 208s 164ms/step - loss: 4.9874 - categorical_accuracy: 0.1918 - val_loss: 5.7274 - val_categorical_accuracy: 0.1804\n",
            "Epoch 13/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.9167 - categorical_accuracy: 0.1947\n",
            "Epoch 13: saving model to /content/model/checkpoint/model-13.keras\n",
            "1273/1273 [==============================] - 204s 160ms/step - loss: 4.9167 - categorical_accuracy: 0.1947 - val_loss: 5.7821 - val_categorical_accuracy: 0.1814\n",
            "Epoch 14/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.8480 - categorical_accuracy: 0.1973\n",
            "Epoch 14: saving model to /content/model/checkpoint/model-14.keras\n",
            "1273/1273 [==============================] - 211s 166ms/step - loss: 4.8480 - categorical_accuracy: 0.1973 - val_loss: 5.8584 - val_categorical_accuracy: 0.1826\n",
            "Epoch 15/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.7816 - categorical_accuracy: 0.1998\n",
            "Epoch 15: saving model to /content/model/checkpoint/model-15.keras\n",
            "1273/1273 [==============================] - 205s 161ms/step - loss: 4.7816 - categorical_accuracy: 0.1998 - val_loss: 5.9439 - val_categorical_accuracy: 0.1834\n",
            "Epoch 16/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.7171 - categorical_accuracy: 0.2023\n",
            "Epoch 16: saving model to /content/model/checkpoint/model-16.keras\n",
            "1273/1273 [==============================] - 212s 167ms/step - loss: 4.7171 - categorical_accuracy: 0.2023 - val_loss: 6.0428 - val_categorical_accuracy: 0.1829\n",
            "Epoch 17/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.6549 - categorical_accuracy: 0.2045\n",
            "Epoch 17: saving model to /content/model/checkpoint/model-17.keras\n",
            "1273/1273 [==============================] - 204s 160ms/step - loss: 4.6549 - categorical_accuracy: 0.2045 - val_loss: 6.1423 - val_categorical_accuracy: 0.1823\n",
            "Epoch 18/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.5960 - categorical_accuracy: 0.2068\n",
            "Epoch 18: saving model to /content/model/checkpoint/model-18.keras\n",
            "1273/1273 [==============================] - 201s 158ms/step - loss: 4.5960 - categorical_accuracy: 0.2068 - val_loss: 6.2657 - val_categorical_accuracy: 0.1830\n",
            "Epoch 19/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.5382 - categorical_accuracy: 0.2089\n",
            "Epoch 19: saving model to /content/model/checkpoint/model-19.keras\n",
            "1273/1273 [==============================] - 201s 158ms/step - loss: 4.5382 - categorical_accuracy: 0.2089 - val_loss: 6.3893 - val_categorical_accuracy: 0.1825\n",
            "Epoch 20/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.4823 - categorical_accuracy: 0.2112\n",
            "Epoch 20: saving model to /content/model/checkpoint/model-20.keras\n",
            "1273/1273 [==============================] - 206s 162ms/step - loss: 4.4823 - categorical_accuracy: 0.2112 - val_loss: 6.5283 - val_categorical_accuracy: 0.1825\n",
            "Epoch 21/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.4304 - categorical_accuracy: 0.2139\n",
            "Epoch 21: saving model to /content/model/checkpoint/model-21.keras\n",
            "1273/1273 [==============================] - 205s 161ms/step - loss: 4.4304 - categorical_accuracy: 0.2139 - val_loss: 6.6598 - val_categorical_accuracy: 0.1817\n",
            "Epoch 22/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.3787 - categorical_accuracy: 0.2169\n",
            "Epoch 22: saving model to /content/model/checkpoint/model-22.keras\n",
            "1273/1273 [==============================] - 205s 161ms/step - loss: 4.3787 - categorical_accuracy: 0.2169 - val_loss: 6.7876 - val_categorical_accuracy: 0.1804\n",
            "Epoch 23/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.3278 - categorical_accuracy: 0.2196\n",
            "Epoch 23: saving model to /content/model/checkpoint/model-23.keras\n",
            "1273/1273 [==============================] - 212s 167ms/step - loss: 4.3278 - categorical_accuracy: 0.2196 - val_loss: 6.9009 - val_categorical_accuracy: 0.1818\n",
            "Epoch 24/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.2815 - categorical_accuracy: 0.2229\n",
            "Epoch 24: saving model to /content/model/checkpoint/model-24.keras\n",
            "1273/1273 [==============================] - 217s 171ms/step - loss: 4.2815 - categorical_accuracy: 0.2229 - val_loss: 7.0409 - val_categorical_accuracy: 0.1801\n",
            "Epoch 25/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.2364 - categorical_accuracy: 0.2256\n",
            "Epoch 25: saving model to /content/model/checkpoint/model-25.keras\n",
            "1273/1273 [==============================] - 212s 166ms/step - loss: 4.2364 - categorical_accuracy: 0.2256 - val_loss: 7.1513 - val_categorical_accuracy: 0.1786\n",
            "Epoch 26/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.1926 - categorical_accuracy: 0.2290\n",
            "Epoch 26: saving model to /content/model/checkpoint/model-26.keras\n",
            "1273/1273 [==============================] - 205s 161ms/step - loss: 4.1926 - categorical_accuracy: 0.2290 - val_loss: 7.2797 - val_categorical_accuracy: 0.1787\n",
            "Epoch 27/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.1497 - categorical_accuracy: 0.2323\n",
            "Epoch 27: saving model to /content/model/checkpoint/model-27.keras\n",
            "1273/1273 [==============================] - 207s 163ms/step - loss: 4.1497 - categorical_accuracy: 0.2323 - val_loss: 7.3961 - val_categorical_accuracy: 0.1777\n",
            "Epoch 28/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.1074 - categorical_accuracy: 0.2353\n",
            "Epoch 28: saving model to /content/model/checkpoint/model-28.keras\n",
            "1273/1273 [==============================] - 215s 169ms/step - loss: 4.1074 - categorical_accuracy: 0.2353 - val_loss: 7.5356 - val_categorical_accuracy: 0.1772\n",
            "Epoch 29/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.0657 - categorical_accuracy: 0.2388\n",
            "Epoch 29: saving model to /content/model/checkpoint/model-29.keras\n",
            "1273/1273 [==============================] - 212s 166ms/step - loss: 4.0657 - categorical_accuracy: 0.2388 - val_loss: 7.6300 - val_categorical_accuracy: 0.1776\n",
            "Epoch 30/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 4.0266 - categorical_accuracy: 0.2424\n",
            "Epoch 30: saving model to /content/model/checkpoint/model-30.keras\n",
            "1273/1273 [==============================] - 212s 166ms/step - loss: 4.0266 - categorical_accuracy: 0.2424 - val_loss: 7.7713 - val_categorical_accuracy: 0.1765\n",
            "Epoch 31/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 3.9907 - categorical_accuracy: 0.2453\n",
            "Epoch 31: saving model to /content/model/checkpoint/model-31.keras\n",
            "1273/1273 [==============================] - 211s 166ms/step - loss: 3.9907 - categorical_accuracy: 0.2453 - val_loss: 7.8877 - val_categorical_accuracy: 0.1762\n",
            "Epoch 32/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 3.9539 - categorical_accuracy: 0.2485\n",
            "Epoch 32: saving model to /content/model/checkpoint/model-32.keras\n",
            "1273/1273 [==============================] - 200s 157ms/step - loss: 3.9539 - categorical_accuracy: 0.2485 - val_loss: 8.0062 - val_categorical_accuracy: 0.1751\n",
            "Epoch 33/50\n",
            "1273/1273 [==============================] - ETA: 0s - loss: 3.9189 - categorical_accuracy: 0.2520\n",
            "Epoch 33: saving model to /content/model/checkpoint/model-33.keras\n",
            "1273/1273 [==============================] - 209s 164ms/step - loss: 3.9189 - categorical_accuracy: 0.2520 - val_loss: 8.1081 - val_categorical_accuracy: 0.1742\n",
            "Epoch 34/50\n",
            " 329/1273 [======>.......................] - ETA: 2:15 - loss: 3.9097 - categorical_accuracy: 0.2528"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import argmax\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "indexToString = load_dictionary(os.path.join('/content/data/', 'indexToString.json'))\n",
        "stringToIndex = load_dictionary(os.path.join('/content/data/', 'stringToIndex.json'))\n",
        "\n",
        "model = tf.keras.models.load_model(os.path.join('/content/', 'model', 'model.keras'))\n",
        "\n",
        "def predict_next_word(string, verbose=True, NUMBER_OF_PREDICTIONS=1):\n",
        "    ques_bool = False\n",
        "    idx, ques_bool = string_to_indexes(string.split(), ques_bool)\n",
        "\n",
        "    if len(idx) >= CONFIG_number_of_words:\n",
        "        if verbose:\n",
        "            # Reshape the input to match the expected shape (batch_size, num_steps)\n",
        "            prediction = model.predict(np.array([idx[-CONFIG_number_of_words:]]))\n",
        "        else:\n",
        "            prediction = model.predict(np.array([idx[-CONFIG_number_of_words:]]))\n",
        "        best_predictions = []\n",
        "\n",
        "        for _ in range(NUMBER_OF_PREDICTIONS):\n",
        "            argmax_idx = argmax(prediction[:, CONFIG_number_of_words - 1, :])\n",
        "            print(prediction[:, CONFIG_number_of_words - 1, argmax_idx])\n",
        "            best_predictions.append(argmax_idx)\n",
        "            prediction[:, CONFIG_number_of_words - 1, argmax_idx] = 0.0\n",
        "\n",
        "        if verbose:\n",
        "            print('\\nprediction indexes\\t:', best_predictions)\n",
        "        converted_string = indexes_to_string(best_predictions, ques_bool)\n",
        "        sentences = []\n",
        "\n",
        "        for word in converted_string:\n",
        "            sentences.append(string + ' ' + word)\n",
        "        return sentences\n",
        "    else:\n",
        "        print('\\n\\nPlease enter at least', CONFIG_number_of_words, ' words.\\n')\n",
        "\n",
        "\n",
        "def string_to_indexes(array_of_string, ques_bool):\n",
        "    array_of_indexes = []\n",
        "    for word in array_of_string:\n",
        "        if word == '<rare word>':\n",
        "            word = '<unk>'\n",
        "        if word == '.' or word == '?':\n",
        "            word = '<eos>'\n",
        "        if word in ['what', 'why', 'who', 'how', 'whose', 'when', 'which', 'where']:\n",
        "            ques_bool = True\n",
        "\n",
        "        try:\n",
        "            array_of_indexes.append(stringToIndex[word])\n",
        "        except:\n",
        "            print(\"Word \", word, \" does not exist in the vocabulary!\\nReplacing it with '<unk>'\")\n",
        "            word = '<unk>'\n",
        "            array_of_indexes.append(stringToIndex[word])\n",
        "            pass\n",
        "    return array_of_indexes, ques_bool\n",
        "\n",
        "def indexes_to_string(array_of_indexes, ques_bool):\n",
        "    array_of_strings = []\n",
        "\n",
        "    for index in array_of_indexes:\n",
        "        word = indexToString[str(index)]\n",
        "        if word == '<eos>':\n",
        "            if ques_bool:\n",
        "                word = '?'\n",
        "            else:\n",
        "                word = '.'\n",
        "        if word == 'N':\n",
        "            pass\n",
        "        array_of_strings.append(word)\n",
        "    return array_of_strings\n",
        "\n",
        "while True:\n",
        "    sentences = predict_next_word(\n",
        "        string=input('\\n\\nEnter atleast ' + str(CONFIG_number_of_words) +' words: \\n'),\n",
        "        NUMBER_OF_PREDICTIONS=1)\n",
        "    print('\\n')\n",
        "    if sentences:\n",
        "        count = 0\n",
        "        for sentence in sentences:\n",
        "            count += 1\n",
        "            print(count, '\\t-', sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79Y_6S0r8jbE",
        "outputId": "3763cf1d-7337-425c-abd6-87f9194cce0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word  hello  does not exist in the vocabulary!\n",
            "Replacing it with '<unk>'\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "[0.06052542]\n",
            "\n",
            "prediction indexes\t: [1]\n",
            "\n",
            "\n",
            "1 \t- hello this is <unk>\n"
          ]
        }
      ]
    }
  ]
}